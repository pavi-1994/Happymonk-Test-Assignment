{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Note Authantication by using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important libraries require for the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote=pd.read_csv(\"\n",
    "                     BankNote_Authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   variance  1372 non-null   float64\n",
      " 1   skewness  1372 non-null   float64\n",
      " 2   curtosis  1372 non-null   float64\n",
      " 3   entropy   1372 non-null   float64\n",
      " 4   class     1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "banknote.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    0\n",
       "skewness    0\n",
       "curtosis    0\n",
       "entropy     0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = banknote.iloc[:, 0:4].values \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= banknote.iloc[:, 4].values \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spliting the X y into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\chararaj\\anaconda3\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chararaj\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\chararaj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\chararaj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\chararaj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set((1097, 4), (1097,))\n"
     ]
    }
   ],
   "source": [
    "print(\"train set\"+str((X_train.shape, y_train.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test set((275, 4), (275,))\n"
     ]
    }
   ],
   "source": [
    "print(\" test set\"+ str((X_test.shape,y_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### feature scaling the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_x= StandardScaler()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= st_x.fit_transform(X_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= st_x.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model selection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers  import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x27c4894c850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing ANN\n",
    "classifier= Sequential()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hidden layer and hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.add(Dense(units =8, kernel_initializer = 'he_uniform' , activation = 'relu', input_dim =4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1 , kernel_initializer= 'glorot_uniform' , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "74/74 [==============================] - 14s 9ms/step - loss: 0.6216 - accuracy: 0.6852 - val_loss: 0.5057 - val_accuracy: 0.8430\n",
      "Epoch 2/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8606 - val_loss: 0.4057 - val_accuracy: 0.9256\n",
      "Epoch 3/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.9039 - val_loss: 0.3333 - val_accuracy: 0.9587\n",
      "Epoch 4/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.9700 - val_loss: 0.2797 - val_accuracy: 0.9614\n",
      "Epoch 5/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.9487 - val_loss: 0.2376 - val_accuracy: 0.9614\n",
      "Epoch 6/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9656 - val_loss: 0.2040 - val_accuracy: 0.9669\n",
      "Epoch 7/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9715 - val_loss: 0.1768 - val_accuracy: 0.9697\n",
      "Epoch 8/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9839 - val_loss: 0.1545 - val_accuracy: 0.9725\n",
      "Epoch 9/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9812 - val_loss: 0.1365 - val_accuracy: 0.9752\n",
      "Epoch 10/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9804 - val_loss: 0.1218 - val_accuracy: 0.9807\n",
      "Epoch 11/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9802 - val_loss: 0.1092 - val_accuracy: 0.9807\n",
      "Epoch 12/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9778 - val_loss: 0.0988 - val_accuracy: 0.9807\n",
      "Epoch 13/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9848 - val_loss: 0.0900 - val_accuracy: 0.9807\n",
      "Epoch 14/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9779 - val_loss: 0.0826 - val_accuracy: 0.9807\n",
      "Epoch 15/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9810 - val_loss: 0.0763 - val_accuracy: 0.9807\n",
      "Epoch 16/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9784 - val_loss: 0.0711 - val_accuracy: 0.9807\n",
      "Epoch 17/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9780 - val_loss: 0.0665 - val_accuracy: 0.9807\n",
      "Epoch 18/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9839 - val_loss: 0.0626 - val_accuracy: 0.9807\n",
      "Epoch 19/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9733 - val_loss: 0.0592 - val_accuracy: 0.9807\n",
      "Epoch 20/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9807\n",
      "Epoch 21/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9814 - val_loss: 0.0536 - val_accuracy: 0.9807\n",
      "Epoch 22/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9876 - val_loss: 0.0513 - val_accuracy: 0.9807\n",
      "Epoch 23/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 0.0494 - val_accuracy: 0.9807\n",
      "Epoch 24/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0474 - val_accuracy: 0.9807\n",
      "Epoch 25/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.0457 - val_accuracy: 0.9807\n",
      "Epoch 26/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0442 - val_accuracy: 0.9807\n",
      "Epoch 27/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 0.0427 - val_accuracy: 0.9835\n",
      "Epoch 28/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9826 - val_loss: 0.0415 - val_accuracy: 0.9835\n",
      "Epoch 29/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9717 - val_loss: 0.0401 - val_accuracy: 0.9835\n",
      "Epoch 30/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9798 - val_loss: 0.0391 - val_accuracy: 0.9835\n",
      "Epoch 31/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9819 - val_loss: 0.0381 - val_accuracy: 0.9835\n",
      "Epoch 32/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9820 - val_loss: 0.0373 - val_accuracy: 0.9835\n",
      "Epoch 33/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.0363 - val_accuracy: 0.9835\n",
      "Epoch 34/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0352 - val_accuracy: 0.9835\n",
      "Epoch 35/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9827 - val_loss: 0.0346 - val_accuracy: 0.9835\n",
      "Epoch 36/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9839 - val_loss: 0.0335 - val_accuracy: 0.9835\n",
      "Epoch 37/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9824 - val_loss: 0.0328 - val_accuracy: 0.9835\n",
      "Epoch 38/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.0322 - val_accuracy: 0.9835\n",
      "Epoch 39/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9852 - val_loss: 0.0313 - val_accuracy: 0.9835\n",
      "Epoch 40/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9840 - val_loss: 0.0308 - val_accuracy: 0.9835\n",
      "Epoch 41/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9935 - val_loss: 0.0302 - val_accuracy: 0.9835\n",
      "Epoch 42/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 0.0294 - val_accuracy: 0.9835\n",
      "Epoch 43/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 0.0286 - val_accuracy: 0.9835\n",
      "Epoch 44/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9856 - val_loss: 0.0280 - val_accuracy: 0.9835\n",
      "Epoch 45/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.0277 - val_accuracy: 0.9835\n",
      "Epoch 46/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.0271 - val_accuracy: 0.9835\n",
      "Epoch 47/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.0262 - val_accuracy: 0.9835\n",
      "Epoch 48/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9841 - val_loss: 0.0257 - val_accuracy: 0.9835\n",
      "Epoch 49/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9853 - val_loss: 0.0252 - val_accuracy: 0.9835\n",
      "Epoch 50/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 0.0247 - val_accuracy: 0.9835\n",
      "Epoch 51/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9901 - val_loss: 0.0240 - val_accuracy: 0.9835\n",
      "Epoch 52/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0236 - val_accuracy: 0.9917\n",
      "Epoch 53/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.0227 - val_accuracy: 0.9917\n",
      "Epoch 54/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 0.0222 - val_accuracy: 0.9917\n",
      "Epoch 55/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0219 - val_accuracy: 0.9917\n",
      "Epoch 56/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9962 - val_loss: 0.0214 - val_accuracy: 0.9945\n",
      "Epoch 57/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.0209 - val_accuracy: 0.9945\n",
      "Epoch 58/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9970 - val_loss: 0.0205 - val_accuracy: 0.9945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.0198 - val_accuracy: 0.9945\n",
      "Epoch 60/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9908 - val_loss: 0.0193 - val_accuracy: 0.9945\n",
      "Epoch 61/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9996 - val_loss: 0.0191 - val_accuracy: 0.9945\n",
      "Epoch 62/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.0187 - val_accuracy: 0.9945\n",
      "Epoch 63/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.0182 - val_accuracy: 0.9945\n",
      "Epoch 64/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0180 - val_accuracy: 0.9945\n",
      "Epoch 65/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9992 - val_loss: 0.0173 - val_accuracy: 0.9945\n",
      "Epoch 66/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9986 - val_loss: 0.0168 - val_accuracy: 0.9945\n",
      "Epoch 67/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.0162 - val_accuracy: 0.9945\n",
      "Epoch 68/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9945\n",
      "Epoch 69/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9945\n",
      "Epoch 70/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9992 - val_loss: 0.0149 - val_accuracy: 0.9945\n",
      "Epoch 71/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9945\n",
      "Epoch 72/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9945\n",
      "Epoch 73/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9945\n",
      "Epoch 74/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9945\n",
      "Epoch 75/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9945\n",
      "Epoch 76/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9945\n",
      "Epoch 77/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9945\n",
      "Epoch 78/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9945\n",
      "Epoch 79/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9945\n",
      "Epoch 80/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9945\n",
      "Epoch 81/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9945\n",
      "Epoch 82/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9945\n",
      "Epoch 83/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9945\n",
      "Epoch 84/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9945\n",
      "Epoch 85/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9945\n",
      "Epoch 86/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9945\n",
      "Epoch 87/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9945\n",
      "Epoch 88/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9945\n",
      "Epoch 89/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9945\n",
      "Epoch 90/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9945\n",
      "Epoch 91/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9945\n",
      "Epoch 92/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9945\n",
      "Epoch 93/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9945\n",
      "Epoch 94/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9945\n",
      "Epoch 95/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9945\n",
      "Epoch 96/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000   - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 9.4264e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 8.5925e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.3348e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 8.7970e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 8.5204e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 7.9445e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.2908e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 9.9698e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 7.5080e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.1664e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.9845e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 7.2564e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.2253e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 7.6351e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.6305e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.7968e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.4599e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.4339e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.1117e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 4.6409e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.1372e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.5404e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 7.2653e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.7210e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 5.0159e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.9027e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.2266e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.6250e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.2211e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.6746e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.1158e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.5387e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.6563e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.7615e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.4112e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.2948e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.3203e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.1958e-04 - accuracy: 1.0000 - val_loss: 9.4298e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.3592e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.4756e-04 - accuracy: 1.0000 - val_loss: 9.4140e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.1942e-04 - accuracy: 1.0000 - val_loss: 9.4183e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.5609e-04 - accuracy: 1.0000 - val_loss: 8.7603e-04 - val_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.2831e-04 - accuracy: 1.0000 - val_loss: 8.7761e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.6536e-04 - accuracy: 1.0000 - val_loss: 8.8481e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9137e-04 - accuracy: 1.0000 - val_loss: 8.7516e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.4149e-04 - accuracy: 1.0000 - val_loss: 8.2436e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.1464e-04 - accuracy: 1.0000 - val_loss: 8.0334e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.5269e-04 - accuracy: 1.0000 - val_loss: 8.0691e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.8749e-04 - accuracy: 1.0000 - val_loss: 7.8116e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.5779e-04 - accuracy: 1.0000 - val_loss: 8.1063e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.2374e-04 - accuracy: 1.0000 - val_loss: 7.4414e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.1950e-04 - accuracy: 1.0000 - val_loss: 8.1939e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.0149e-04 - accuracy: 1.0000 - val_loss: 8.0338e-04 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.0956e-04 - accuracy: 1.0000 - val_loss: 7.6461e-04 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9911e-04 - accuracy: 1.0000 - val_loss: 7.7343e-04 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.8157e-04 - accuracy: 1.0000 - val_loss: 7.4070e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2858e-04 - accuracy: 1.0000 - val_loss: 7.4820e-04 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.8616e-04 - accuracy: 1.0000 - val_loss: 7.2751e-04 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.9035e-04 - accuracy: 1.0000 - val_loss: 7.2362e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.8784e-04 - accuracy: 1.0000 - val_loss: 6.8003e-04 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.7571e-04 - accuracy: 1.0000 - val_loss: 6.7771e-04 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0552e-04 - accuracy: 1.0000 - val_loss: 6.8102e-04 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.1305e-04 - accuracy: 1.0000 - val_loss: 6.3888e-04 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4005e-04 - accuracy: 1.0000 - val_loss: 6.4778e-04 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.3376e-04 - accuracy: 1.0000 - val_loss: 6.4945e-04 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.4844e-04 - accuracy: 1.0000 - val_loss: 6.5462e-04 - val_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.6111e-04 - accuracy: 1.0000 - val_loss: 6.4256e-04 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.4760e-04 - accuracy: 1.0000 - val_loss: 6.2586e-04 - val_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 9.2043e-05 - accuracy: 1.0000 - val_loss: 6.3130e-04 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.2676e-04 - accuracy: 1.0000 - val_loss: 6.3202e-04 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.6312e-04 - accuracy: 1.0000 - val_loss: 6.1822e-04 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4995e-04 - accuracy: 1.0000 - val_loss: 6.2153e-04 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4462e-04 - accuracy: 1.0000 - val_loss: 5.8866e-04 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4820e-04 - accuracy: 1.0000 - val_loss: 5.9098e-04 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.5969e-04 - accuracy: 1.0000 - val_loss: 5.7824e-04 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.5979e-04 - accuracy: 1.0000 - val_loss: 5.9188e-04 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.7345e-04 - accuracy: 1.0000 - val_loss: 6.0573e-04 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0120e-04 - accuracy: 1.0000 - val_loss: 5.8120e-04 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.7409e-04 - accuracy: 1.0000 - val_loss: 5.7174e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 9.6458e-05 - accuracy: 1.0000 - val_loss: 5.7318e-04 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 9.8257e-05 - accuracy: 1.0000 - val_loss: 5.3962e-04 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.2410e-04 - accuracy: 1.0000 - val_loss: 5.1603e-04 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.8972e-05 - accuracy: 1.0000 - val_loss: 5.0732e-04 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1829e-04 - accuracy: 1.0000 - val_loss: 5.2921e-04 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 8.6374e-05 - accuracy: 1.0000 - val_loss: 5.1090e-04 - val_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.6510e-05 - accuracy: 1.0000 - val_loss: 5.1438e-04 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0985e-04 - accuracy: 1.0000 - val_loss: 4.9004e-04 - val_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 7.6484e-05 - accuracy: 1.0000 - val_loss: 4.7741e-04 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0227e-04 - accuracy: 1.0000 - val_loss: 4.9301e-04 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.3100e-05 - accuracy: 1.0000 - val_loss: 4.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 9.6666e-05 - accuracy: 1.0000 - val_loss: 4.6845e-04 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.8983e-05 - accuracy: 1.0000 - val_loss: 4.6961e-04 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.2108e-05 - accuracy: 1.0000 - val_loss: 4.7315e-04 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1712e-04 - accuracy: 1.0000 - val_loss: 4.4929e-04 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 4.4558e-04 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.6663e-05 - accuracy: 1.0000 - val_loss: 4.6618e-04 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.9995e-05 - accuracy: 1.0000 - val_loss: 4.6669e-04 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.2128e-05 - accuracy: 1.0000 - val_loss: 4.4175e-04 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.0318e-05 - accuracy: 1.0000 - val_loss: 4.1978e-04 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 9.6231e-05 - accuracy: 1.0000 - val_loss: 4.3244e-04 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.8551e-05 - accuracy: 1.0000 - val_loss: 4.3364e-04 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.7614e-05 - accuracy: 1.0000 - val_loss: 4.2579e-04 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 7.3313e-05 - accuracy: 1.0000 - val_loss: 4.3215e-04 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.8876e-05 - accuracy: 1.0000 - val_loss: 4.2751e-04 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 7.0574e-05 - accuracy: 1.0000 - val_loss: 4.1351e-04 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.1359e-05 - accuracy: 1.0000 - val_loss: 4.0682e-04 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.2337e-05 - accuracy: 1.0000 - val_loss: 4.0378e-04 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.8011e-05 - accuracy: 1.0000 - val_loss: 3.9693e-04 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.7972e-05 - accuracy: 1.0000 - val_loss: 4.0892e-04 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.4685e-05 - accuracy: 1.0000 - val_loss: 3.9472e-04 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.8964e-05 - accuracy: 1.0000 - val_loss: 3.8707e-04 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.2852e-05 - accuracy: 1.0000 - val_loss: 4.0996e-04 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.0192e-05 - accuracy: 1.0000 - val_loss: 3.9051e-04 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 7.2491e-05 - accuracy: 1.0000 - val_loss: 3.9537e-04 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 5.1569e-05 - accuracy: 1.0000 - val_loss: 3.7361e-04 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 4.6582e-05 - accuracy: 1.0000 - val_loss: 3.8516e-04 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.2941e-05 - accuracy: 1.0000 - val_loss: 3.6102e-04 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.7161e-05 - accuracy: 1.0000 - val_loss: 3.5195e-04 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 6.2450e-05 - accuracy: 1.0000 - val_loss: 3.7256e-04 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.2009e-05 - accuracy: 1.0000 - val_loss: 3.6501e-04 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.0709e-05 - accuracy: 1.0000 - val_loss: 3.8069e-04 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.4150e-05 - accuracy: 1.0000 - val_loss: 3.6260e-04 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 8.5964e-05 - accuracy: 1.0000 - val_loss: 3.5840e-04 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.7534e-05 - accuracy: 1.0000 - val_loss: 3.5895e-04 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.3168e-05 - accuracy: 1.0000 - val_loss: 3.4627e-04 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.2507e-05 - accuracy: 1.0000 - val_loss: 3.5016e-04 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.0733e-05 - accuracy: 1.0000 - val_loss: 3.5539e-04 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.4606e-05 - accuracy: 1.0000 - val_loss: 3.3231e-04 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.3771e-05 - accuracy: 1.0000 - val_loss: 3.3611e-04 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.3075e-05 - accuracy: 1.0000 - val_loss: 3.2603e-04 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.8296e-05 - accuracy: 1.0000 - val_loss: 3.2995e-04 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.5989e-05 - accuracy: 1.0000 - val_loss: 3.2117e-04 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.9706e-05 - accuracy: 1.0000 - val_loss: 3.2786e-04 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 1ms/step - loss: 2.5980e-05 - accuracy: 1.0000 - val_loss: 3.3958e-04 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.2222e-05 - accuracy: 1.0000 - val_loss: 3.2087e-04 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.3218e-05 - accuracy: 1.0000 - val_loss: 3.2977e-04 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 5.1311e-05 - accuracy: 1.0000 - val_loss: 2.9943e-04 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.1290e-05 - accuracy: 1.0000 - val_loss: 2.9662e-04 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.1748e-05 - accuracy: 1.0000 - val_loss: 2.9901e-04 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.4681e-05 - accuracy: 1.0000 - val_loss: 3.0797e-04 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.3682e-05 - accuracy: 1.0000 - val_loss: 2.8763e-04 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.6209e-05 - accuracy: 1.0000 - val_loss: 3.0965e-04 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.7165e-05 - accuracy: 1.0000 - val_loss: 3.0109e-04 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9695e-05 - accuracy: 1.0000 - val_loss: 2.8223e-04 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9077e-05 - accuracy: 1.0000 - val_loss: 3.0110e-04 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.0781e-05 - accuracy: 1.0000 - val_loss: 3.1247e-04 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.3966e-05 - accuracy: 1.0000 - val_loss: 3.0625e-04 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.1091e-05 - accuracy: 1.0000 - val_loss: 2.9183e-04 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 3.9131e-05 - accuracy: 1.0000 - val_loss: 2.8626e-04 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.6218e-05 - accuracy: 1.0000 - val_loss: 2.9221e-04 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.3175e-05 - accuracy: 1.0000 - val_loss: 2.9788e-04 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4851e-05 - accuracy: 1.0000 - val_loss: 2.7982e-04 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.8593e-05 - accuracy: 1.0000 - val_loss: 2.7958e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_epoch=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_epoch.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   0],\n",
       "       [  0, 117]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n",
      "Precision: 1.000000\n",
      "Recall: 1.000000\n",
      "F1 score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ploting graph loss vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm40lEQVR4nO3deZxddX3/8dfn3tmXJJOZCZDJNkBYEpYAIaBYK1UgAUukKCJiW6tGfg9p66NqhbbSn21t8ddq3dAYNK2tFkpFFCWUTUBaQbIYICGJCSEhk3UyWWafucvn98c5M9xMZiYzSc7cmTnv5+MxjznrvZ/DIfc93+8593vM3RERkfhK5LsAERHJLwWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJAZIjM7F/N7O+GuO02M3vXib6OyEhQEIiIxJyCQEQk5hQEMq6EXTKfMbOXzazNzL5rZqeY2aNm1mJmT5pZVc7215vZejM7ZGbPmNm5OesuMrM14X7/CZT0ea93m9nacN9fmtkFx1nzx8xsi5kdMLOHzWxquNzM7J/NbJ+ZHQ6P6bxw3bVm9mpY204z+/Rx/QcTQUEg49ONwFXAWcDvAo8CfwHUEPw//ycAZnYWcB/wSaAWWAH81MyKzKwI+DHw78Bk4L/C1yXc92JgOfBxoBr4NvCwmRUPp1Az+x3gH4CbgNOA7cD94eqrgbeHxzEJeD/QFK77LvBxd68EzgN+Ppz3FcmlIJDx6OvuvtfddwLPAb9y91+7exfwEHBRuN37gUfc/Ql3TwH/BJQCbwUuBwqBr7h7yt1/CKzMeY+PAd9291+5e8bdvwd0hfsNxweB5e6+JqzvTuAtZjYLSAGVwDmAufsGd98d7pcC5pjZBHc/6O5rhvm+Ir0UBDIe7c2Z7uhnviKcnkrwFzgA7p4FdgB14bqdfuSojNtzpmcCnwq7hQ6Z2SFgerjfcPStoZXgr/46d/858A3gHmCvmS0zswnhpjcC1wLbzexZM3vLMN9XpJeCQOJsF8EHOhD0yRN8mO8EdgN14bIeM3KmdwBfcPdJOT9l7n7fCdZQTtDVtBPA3b/m7pcAcwm6iD4TLl/p7ouBKQRdWA8M831FeikIJM4eAK4zs3eaWSHwKYLunV8CzwNp4E/MrMDMfg9YkLPvvcBtZnZZeFG33MyuM7PKYdbwH8CHzWxeeH3h7wm6sraZ2aXh6xcCbUAnkAmvYXzQzCaGXVrNQOYE/jtIzCkIJLbcfRNwK/B1YD/BheXfdfdud+8Gfg/4Q+AgwfWEH+Xsu4rgOsE3wvVbwm2HW8NTwOeABwlaIWcAN4erJxAEzkGC7qMmgusYAB8CtplZM3BbeBwix8X0YBoRkXhTi0BEJOYUBCIiMacgEBGJOQWBiEjMFeS7gOGqqanxWbNm5bsMEZExZfXq1fvdvba/dWMuCGbNmsWqVavyXYaIyJhiZtsHWqeuIRGRmFMQiIjEnIJARCTmxtw1gv6kUikaGhro7OzMdymRKykpYdq0aRQWFua7FBEZJyINAjNbCHwVSALfcfe7+9nmHcBXCMZ+3+/uvz3c92loaKCyspJZs2Zx5GCR44u709TURENDA/X19fkuR0TGici6hswsSTCO+iJgDvABM5vTZ5tJwDeB6919LvC+43mvzs5Oqqurx3UIAJgZ1dXVsWj5iMjIifIawQJgi7tvDUdyvB9Y3GebW4AfufsbAO6+73jfbLyHQI+4HKeIjJwog6CO4OEdPRrCZbnOAqrCh4avNrPf7++FzGyJma0ys1WNjY3HVUxnKsOew52kM9nj2l9EZLyKMgj6+9O175jXBcAlwHXANcDnwgeKH7mT+zJ3n+/u82tr+/1i3DF1pTLsa+kknT35w24fOnSIb37zm8Pe79prr+XQoUMnvR4RkeGIMggaCB7712MawWP5+m7z3+7e5u77gV8AF0ZRTE+XShTPXxgoCDKZwR8atWLFCiZNmnTS6xERGY4og2AlMNvM6s2siOCpSw/32eYnwG+FjwIsAy4DNkRRTE/XegQNAu644w5ee+015s2bx6WXXsqVV17JLbfcwvnnnw/Ae97zHi655BLmzp3LsmXLevebNWsW+/fvZ9u2bZx77rl87GMfY+7cuVx99dV0dHSc/EJFRPoR2e2j7p42s9uBxwhuH13u7uvN7LZw/VJ332Bm/w28DGQJbjFddyLv+/mfrufVXc1HLc9knc5UhpKiJMlhXnCdM3UCf/27cwdcf/fdd7Nu3TrWrl3LM888w3XXXce6det6b/Fcvnw5kydPpqOjg0svvZQbb7yR6urqI15j8+bN3Hfffdx7773cdNNNPPjgg9x6q54+KCLRi/R7BO6+AljRZ9nSPvP/CPxjlHXAmy0CnP6vXpxECxYsOOI+/6997Ws89NBDAOzYsYPNmzcfFQT19fXMmzcPgEsuuYRt27ZFW6SISGhcfLM410B/ubd3p9myr5VZ1eVMKI32W7nl5eW908888wxPPvkkzz//PGVlZbzjHe/o93sAxcXFvdPJZFJdQyIyYmIz1pCFzYAILhFQWVlJS0tLv+sOHz5MVVUVZWVlbNy4kRdeeCGCCkREjt+4axEMpKdrKIq7hqqrq7niiis477zzKC0t5ZRTTuldt3DhQpYuXcoFF1zA2WefzeWXX37S319E5ERYFB+MUZo/f773fTDNhg0bOPfccwfdryudYdOeFqZXlVFVXhRliZEbyvGKiOQys9XuPr+/dTHsGhpbwSciErX4BEFv11B+6xARGW1iFwRRfKFMRGQsi00QJNQ1JCLSr9gEgbqGRET6F5sg6KEgEBE5UmyCwMwws0i6ho53GGqAr3zlK7S3t5/kikREhi42QQDBwUbRIlAQiMhYFptvFkPQKogiCHKHob7qqquYMmUKDzzwAF1dXdxwww18/vOfp62tjZtuuomGhgYymQyf+9zn2Lt3L7t27eLKK6+kpqaGp59++uQXJyJyDOMvCB69A/a80u+qmd1pChIGBcnhveap58OiuwdcnTsM9eOPP84Pf/hDXnzxRdyd66+/nl/84hc0NjYydepUHnnkESAYg2jixIl8+ctf5umnn6ampmZ4NYmInCSx6hoyohl0Ltfjjz/O448/zkUXXcTFF1/Mxo0b2bx5M+effz5PPvkkn/3sZ3nuueeYOHFixJWIiAzN+GsRDPKX+449LZQWJphRXT7gNifK3bnzzjv5+Mc/ftS61atXs2LFCu68806uvvpq7rrrrsjqEBEZqni1CCz6YaivueYali9fTmtrKwA7d+5k37597Nq1i7KyMm699VY+/elPs2bNmqP2FRHJh/HXIhiEEc1dQ7nDUC9atIhbbrmFt7zlLQBUVFTw/e9/ny1btvCZz3yGRCJBYWEh3/rWtwBYsmQJixYt4rTTTtPFYhHJi9gMQw2wZV8rCYPTayuiKm9EaBhqERkuDUMdiqprSERkLItXEKAhJkRE+ho3QTCULq6EWSSPqhxJY71+ERl9xkUQlJSU0NTUdMwPybHeNeTuNDU1UVJSku9SRGQcGRd3DU2bNo2GhgYaGxsH3e5AWzepTJbMgbH7QVpSUsK0adPyXYaIjCORBoGZLQS+CiSB77j73X3WvwP4CfB6uOhH7v43w32fwsJC6uvrB99ozys8/eQ3+VLbNfzsjt8b7luIiIxbkQWBmSWBe4CrgAZgpZk97O6v9tn0OXd/d1R19Gp6jSub7ufeggWRv5WIyFgS5TWCBcAWd9/q7t3A/cDiCN9vcAVBd5BluvJWgojIaBRlENQBO3LmG8Jlfb3FzF4ys0fNbG5/L2RmS8xslZmtOtZ1gAEVFAOQzHYf3/4iIuNUlEFg/Szre9POGmCmu18IfB34cX8v5O7L3H2+u8+vra09vmrCFkEiqxaBiEiuKIOgAZieMz8N2JW7gbs3u3trOL0CKDSzaAbmz2kR6F58EZE3RRkEK4HZZlZvZkXAzcDDuRuY2almZuH0grCepkiqCVsERZ4ik1UQiIj0iOyuIXdPm9ntwGMEt48ud/f1ZnZbuH4p8F7g/5hZGugAbvao/lwPWwTFpOjOZClIjovv0omInLBIv0cQdves6LNsac70N4BvRFlDr7BFUGwpUmmHohF5VxGRUS8+fxb3tgi66c5k81yMiMjoEcMgSJFSEIiI9IpREIRdQwoCEZEjxCcIEgU4ieAagYJARKRXfILAjEyymCJSdKYUBCIiPeITBIAniykmRVdaQSAi0iOeQZDK5LsUEZFRI15BUFBMsalFICKSK1ZBQLKYYrrpVItARKRXvIKgMOga6kwrCEREesQqCKygJAgC3TUkItIrXkFQWEKxpdQ1JCKSI1ZBkCgsoUi3j4qIHCF2QRB0DalFICLSI1ZBYAUllJiuEYiI5IpVENAbBGoRiIj0iFkQFIVDTCgIRER6xCwIdPuoiEhfMQuC4vCuIbUIRER6xCwISigkTVd3Ot+ViIiMGjELguBxlelUZ54LEREZPWIWBMHjKrPdHXkuRERk9IhZEAQtgmyqK8+FiIiMHjELgqBFQFpdQyIiPSINAjNbaGabzGyLmd0xyHaXmlnGzN4bZT0kiwBwXSMQEekVWRCYWRK4B1gEzAE+YGZzBtjui8BjUdXSq7A0eM+MgkBEpEeULYIFwBZ33+ru3cD9wOJ+tvtj4EFgX4S1BMIgSKZ1sVhEpEeUQVAH7MiZbwiX9TKzOuAGYOlgL2RmS8xslZmtamxsPP6KCssBBYGISK4og8D6WeZ95r8CfNbdB/2qr7svc/f57j6/trb2+CsqKgt+eSfpjIaZEBEBKIjwtRuA6Tnz04BdfbaZD9xvZgA1wLVmlnb3H0dSUWEQBGV00ZXOUpCM101TIiL9iTIIVgKzzawe2AncDNySu4G71/dMm9m/Aj+LLATgzSCwLjpTGcqLozx8EZGxIbJPQndPm9ntBHcDJYHl7r7ezG4L1w96XSASYddQKV106nGVIiJAtC0C3H0FsKLPsn4DwN3/MMpagN6LxWV06eE0IiKheHWSJwvIJgopNQWBiEiPeAUBkCkoC7qGFAQiIkAMg8ALSimji7YuBYGICMQxCArLKLMu2rr0cBoREYhhEFhR0DXU1q0WgYgIxDIIyimli3Y9rlJEBIhhECSKyymzLlrVNSQiAsQ0CErpol0Xi0VEgBgGgRWWUW5dtKlrSEQEiGEQoLuGRESOEL8gCC8W664hEZFA/IKgMLh9tL0zle9KRERGhfgFQTgCaaqrPc+FiIiMDvELgnAE0kxXW54LEREZHWIYBMED7L1bQSAiAnEMgrBrSEEgIhKIYRBUAGAKAhERII5BUFwJQGG6jWzW81yMiEj+xTAIJgBQTgcdejiNiEgcgyBoEVRau4aZEBEhjkFQErQIJtCugedERIhjEIRdQxV0aChqERGGGARm9qdmNsEC3zWzNWZ2ddTFRSKRJFNQRqW1KwhERBh6i+CP3L0ZuBqoBT4M3B1ZVRHLFlVSSQfNHRpvSERkqEFg4e9rgX9x95dylg28k9lCM9tkZlvM7I5+1i82s5fNbK2ZrTKztw299BNQPIEKa6e5Uy0CEZGhBsFqM3ucIAgeM7NKIDvYDmaWBO4BFgFzgA+Y2Zw+mz0FXOju84A/Ar4zjNqPm5VMoJIODqtFICJCwRC3+wgwD9jq7u1mNpmge2gwC4At7r4VwMzuBxYDr/Zs4O6tOduXAyPyDa9k6UQq7Q11DYmIMPQWwVuATe5+yMxuBf4KOHyMfeqAHTnzDeGyI5jZDWa2EXiEoFVwFDNbEnYdrWpsbBxiyQOzkglMtA6a9UwCEZEhB8G3gHYzuxD4c2A78G/H2Ke/awhH/cXv7g+5+znAe4C/7e+F3H2Zu8939/m1tbVDLHkQxZVMsHZ1DYmIMPQgSLu7E3TtfNXdvwpUHmOfBmB6zvw0YNdAG7v7L4AzzKxmiDUdv5KJlNNBc4cuFouIDDUIWszsTuBDwCPhheDCY+yzEphtZvVmVgTcDDycu4GZnWlmFk5fDBQBTcM5gONSPIFSOmnt6Iz8rURERruhXix+P3ALwfcJ9pjZDOAfB9vB3dNmdjvwGJAElrv7ejO7LVy/FLgR+H0zSwEdwPvDlke0wvGG0u3HuswhIjL+DSkIwg//HwCXmtm7gRfd/VjXCHD3FcCKPsuW5kx/Efji8Eo+CcLxhrKdzSP+1iIio81Qh5i4CXgReB9wE/ArM3tvlIVFKhxviE61CEREhto19JfApe6+D8DMaoEngR9GVVikSiYCUJhqJZ3JUpCM39h7IiI9hvoJmOgJgVDTMPYdfUqrAJhkLbRomAkRibmhtgj+28weA+4L599Pn77/MaVsMgBV1srhjhRV5UV5LkhEJH+GerH4M2Z2I3AFwRfFlrn7Q5FWFqXSIAgm0apvF4tI7A21RYC7Pwg8GGEtI6ewlGyiiEnWysF2BYGIxNugQWBmLfQ/EJwB7u4TIqkqamZkSydT1d3KwbbufFcjIpJXgwaBux9rGIkxy8omM6m5lQYFgYjE3Ni98+cEJcqqqLJWDrR15bsUEZG8im0QWNlkqhOtHFCLQERiLrZBQOnksEWgIBCReItvEJRNZoK3cqBVXUMiEm/xDYLSKgpI096m8YZEJN5iHATBl8q87UCeCxERya/4BkE4zESy6yDpTDbPxYiI5E+Mg6AagMm0cEjPLhaRGItvEJTXAlDDYd05JCKxFt8gqDgFgBo7zH7dOSQiMRbfICiuIFtQSo0dprFFQSAi8RXfIAAon0KtHWJfs4JAROIr1kFgladwSqKZvc2d+S5FRCRv4h0EFVOCIFDXkIjEWKyDgIop1NhhtQhEJNbiHQTlU6jINtN0uDXflYiI5E2kQWBmC81sk5ltMbM7+ln/QTN7Ofz5pZldGGU9R6moJYGTbm3Evb8HsYmIjH+RBYGZJYF7gEXAHOADZjanz2avA7/t7hcAfwssi6qefoXfJahIHaS1Kz2iby0iMlpE2SJYAGxx963u3g3cDyzO3cDdf+nuB8PZF4BpEdZztDAIau0ge3ULqYjEVJRBUAfsyJlvCJcN5CPAoxHWc7QJQTlT7YAuGItIbA368PoTZP0s67cj3syuJAiCtw2wfgmwBGDGjBknqz6oPBW3JKdZEzsPdZy81xURGUOibBE0ANNz5qcBu/puZGYXAN8BFrt7U38v5O7L3H2+u8+vra09eRUmklB5KlOtiZ0HFQQiEk9RBsFKYLaZ1ZtZEXAz8HDuBmY2A/gR8CF3/02EtQzIJtQxs+AgDQoCEYmpyLqG3D1tZrcDjwFJYLm7rzez28L1S4G7gGrgm2YGkHb3+VHV1K+JddTt/hU7D7WP6NuKiIwWUV4jwN1XACv6LFuaM/1R4KNR1nBME+qozu5n50EFgYjEU7y/WQwwcRpF3k3X4UYyWX2pTETiR0EQ3kJa603sa9EtpCISPwqCScGNTdOsUReMRSSWFARVswCYbvvY3qTrBCISPwqC0iq8ZBL1ib1sbdQopCISPwoCwCbXc3bRfrY2tuW7FBGREacgAKiqZ4btZet+tQhEJH4UBACT66lJ76OhqVm3kIpI7CgIAKrqSZChJtOoMYdEJHYUBACTTwdglu3hNV0wFpGYURAA1J4NwGzbyau7m/NcjIjIyFIQAJTXQHktF5fs5tVdCgIRiRcFQY/aczi3YJdaBCISOwqCHlPmMC29ndf3t+pB9iISKwqCHlPOpSjTTh372aBWgYjEiIKgx5Q5AJyTeIOXdhzKby0iIiNIQdDjlLlgCa4o28GaNw7muxoRkRGjIOhRXAG153JZ8XZWbz+Iu75hLCLxoCDIVXcRZ3RvYm9zJ7sO6yE1IhIPCoJcdZdQkjrEdNvHqm0H8l2NiMiIUBDkqrsEgLcWvc4LWxUEIhIPCoJcU+ZCUSULJ7zOC1ub8l2NiMiIUBDkShbAjMuYl13P6/vb2H1YI5GKyPinIOhr5hVUtW1lMs38z+b9+a5GRCRyCoK+Zl4BwNUVW/j5xn15LkZEJHqRBoGZLTSzTWa2xczu6Gf9OWb2vJl1mdmno6xlyOouhuKJ3Fi5kV/8ppGudCbfFYmIRCqyIDCzJHAPsAiYA3zAzOb02ewA8CfAP0VVx7AlC+HMd3JBx69o707p7iERGfeibBEsALa4+1Z37wbuBxbnbuDu+9x9JZCKsI7hO2shxZ2NXFb8Bo+8vCvf1YiIRCrKIKgDduTMN4TLhs3MlpjZKjNb1djYeFKKG9TsqyBRwJKadTy6bg+dKXUPicj4FWUQWD/LjmsAH3df5u7z3X1+bW3tCZY1BGWT4fQreWvns7R2duuisYiMa1EGQQMwPWd+GjB2+lnOfy8lbTu5ZsIb/Pvz2/NdjYhIZKIMgpXAbDOrN7Mi4Gbg4Qjf7+Q65zooquCTk5/n+a1NeliNiIxbkQWBu6eB24HHgA3AA+6+3sxuM7PbAMzsVDNrAP4M+CszazCzCVHVNCzFlXDBTZy9/wmmFrXzzWdey3dFIiKRiPR7BO6+wt3Pcvcz3P0L4bKl7r40nN7j7tPcfYK7TwqnR8+f3pd+FEt3cves1fzs5V1s2tOS74pERE46fbN4MKfMhTPfxdsaH6C2OM3fPfKqHlgjIuOOguBY3v7nJDqa+NaZK3lu835WvLIn3xWJiJxUCoJjmXEZnH0dF29fzm+f2s1dP1nH/taufFclInLSKAiGYuHfY57hnkn/QUtXij/+j1+TymTzXZWIyEmhIBiKqlnwzruo2PY4/3nJRp7f2sRdP1mn6wUiMi4oCIbqstvgjHdy0Stf4B8uOsR9L+7gGz/fku+qREROmIJgqBJJeN+/QPWZ3Pz6X7BkToYvPfEb7n50o1oGIjKmKQiGo2QifOB+LFHAnXv/jE+f38nSZ1/jzx54ifbudL6rExE5LgqC4ZpcDx9+FEsW84k3Psk/zz/Ij9fuZPE3/ldfOBORMUlBcDxqz4KPPI5NqOOG9X/Mc/Oeorv1IO/++nP88xO/0VPNRGRMURAcr4l18NEn4aJbmbZhOU+XfIq/nb6arz+1iXd9+Vl+tKaBTFbXDkRk9FMQnIjiCrj+67DkaRLVZ3Lznn/i5VO/wO8k1vKpB37NtV99jhWv7FYgiMioZmPtjpf58+f7qlWr8l3G0dxh/UPwxF/D4Tdorajn3tQ1fPvwZZxSXcWHLp/J9fOmMqWyJN+VikgMmdlqd5/f7zoFwUmWScH6H8ML98CuX5NOlvJiwcXc3zKPZ/0iLpw9kxsumso1c0+lrKgg39WKSEwoCPLBHbb/Etb9EDY+Aq17yVgBL9r5PN51HmuT5zFrzmVce8FULj99MpUlhfmuWETGMQVBvmWz0LASNv4U3/BT7OA2ABqYwqrMmbzks2mpvYipZ13K5WedysUzqigpTOa3ZhEZVxQEo03zLtj0KJnXnia9/UWKO/YC0OmFvORn8BJn0Vp7CZPPuowLzzmbuXWTKCrQdX0ROX4KgtHMHZp3wo4X6dr+Kzpf+yUVB18l6cE3lZu9jC1Mo6H8PNJT51N7xkWcfe4FTJlUkefCRWQsURCMNakO2LWW1m2r2b99Pcm9L3Nq20YKCcKhywvZlpjG/vKzaKt7GzWnX8AZZ1/IxElVeS5cREYrBcF4kO6ia+cr7Nr8a1reeJnCpo1Mbd/ARH9zWIv9VsXBkhlkJp1OyalnUTtrLuWnnR0Mi1FQnMfiRSTfBgsC3b84VhQUUzxzPvUzc85jNkPLjlfYueUVDjZswPdvoaJ1G1N3PUXN7ofg1+FmJGgpPpV01ekUnzKb8tPOxqacC1PmQHktmOXnmERkVFAQjGWJJJUz53HOzHlHLG5q7eJ/tzWwe+t6WndtgKatVLW/wayOXdTvXo291NG7bWfhJFITZ1FYXU9xbT02aQZUzYRJM2HidCgoGuGDEpGRpq6hmGjpTLFxTwubdjezc+cbdO1aT8nBTUxLbWe67WO6NVKX2E8hbw6Y5yRIlZ+KVc2kYFIdNmk6VJ8JE+qClkR5DZRVQ1LfgRAZ7XSNQPrl7jS2drF5byub9rTweuNhDu99g3TT65S3NzDNGplujUy3fZxih5hqTRRw9Miq6eKJUFZDoryGREVPQNQcGRZlk6F4QvBMh+IJkFRjVGQk5e0agZktBL4KJIHvuPvdfdZbuP5aoB34Q3dfE2VN8iYzY0plCVMqS7jizJpw6TwA2rvTvL6/jZ0HO1h/qIMnDney+0Ar6abXyTbvJtHRRLU1U00zk9PNVLe3UL2/mZrETqqthYm0kCQ74Hunk6VkCyvIFldCcSUUVWLFFSSLK0iUVJAoroCi8pyfnPnC8qDLKlkEyeKgRVJQHM73/BTq2ofIEEUWBGaWBO4BrgIagJVm9rC7v5qz2SJgdvhzGfCt8LfkWVlRAXOnTmTu1Il91lwKQFc6w57DnTS2dNHU1s2Btm62t3Wzv7WLA23dHGztJNN+gMLOAxR1HaC4+zDF2VYqaaeCDirTHVR2tVPZ1k4lHZRaIxXsoIxOyq0z/N11QseQtkKyVkgmUUi296eITLKUTEEp2UQhWAGeSOKJArAEJAogkcQt+E3vugJIFGCJJG5JLPnm9pZIQrIAs2Qwn0wGyyyJJRIkEuH8EdNJEhZMBz8WrksE0z3rzAALlycBC97XEkHQWc78UesSOevofx39bEd/vQT2ZrCGNR0xfcRvjp7ufZnBluUsP9YyhfxJFWWLYAGwxd23ApjZ/cBiIDcIFgP/5kH/1AtmNsnMTnP33RHWJSdBcUGSmdXlzKwuH/I+6UyW1q40LZ1pWrvCn840h7vS7E1l6Exl6OjO0JnK0pHK0NWdIt3ZRra7lYJ0O4lUO8l0OwWZdizTDdkUiUwXlk2RyKawTDeJbIqkd5PMpklmg/lC0hSRpsjSFJGihG7K6KLQ2kmSJUmGgvB3MJ+lgAxJC3/3bvPm+p6fhI2trtXxLJsTLh5OH3l27Ih1R64/et/c9bnL6Oe1fYD9j7XtEe87hGzbMuuDXPIHXzz2hsMUZRDUATty5hs4+q/9/rapA44IAjNbAiwBmDFjxkkvVEZGQTLBpLIiJpWN7J1ImayTymTpzmRJpbOkMk7GnWzWcSeYdsfdyWSh251Od7JZyIbrgh/IZoN93YN1mUwGshk8myGbSeHZLJ5J4dkM7lk8k8E9Ey5P456FbIZs+Jtsmmw2C57F3clms3jPfNaBLBauM7KAY+6YZ4Fs8M30cJ15FidYZ3i4Lhuu83Df4DUItzEPX6N3Xc+HlvV+eAX7ZsMV4ev2bulv7k8waT3LIWfbYPue9b1L+6x/8/3oUwVHb9fn4zXnRQfc94hlfuR2zhHtlKPWH/naR9eTu8+R+x3reI485sEU184d0nbDFWUQ9JdvfY92KNvg7suAZRBcLD7x0iROkgkjmUhqID+RAUQ5klkDMD1nfhqw6zi2ERGRCEUZBCuB2WZWb2ZFwM3Aw322eRj4fQtcDhzW9QERkZEVWdeQu6fN7HbgMYLbR5e7+3ozuy1cvxRYQXDr6BaC20c/HFU9IiLSv0i/R+DuKwg+7HOXLc2ZduATUdYgIiKD09NORERiTkEgIhJzCgIRkZhTEIiIxNyYG33UzBqB7ce5ew2w/ySWk086ltFJxzI66VhgprvX9rdizAXBiTCzVQMNwzrW6FhGJx3L6KRjGZy6hkREYk5BICISc3ELgmX5LuAk0rGMTjqW0UnHMohYXSMQEZGjxa1FICIifSgIRERiLjZBYGYLzWyTmW0xszvyXc9wmdk2M3vFzNaa2apw2WQze8LMNoe/q/JdZ3/MbLmZ7TOzdTnLBqzdzO4Mz9MmM7smP1X3b4Bj+b9mtjM8N2vN7NqcdaPyWMxsupk9bWYbzGy9mf1puHzMnZdBjmUsnpcSM3vRzF4Kj+Xz4fJoz4uHj+gbzz8Ew2C/BpwOFAEvAXPyXdcwj2EbUNNn2f8D7gin7wC+mO86B6j97cDFwLpj1Q7MCc9PMVAfnrdkvo/hGMfyf4FP97PtqD0W4DTg4nC6EvhNWO+YOy+DHMtYPC8GVITThcCvgMujPi9xaREsALa4+1Z37wbuBxbnuaaTYTHwvXD6e8B78lfKwNz9F8CBPosHqn0xcL+7d7n76wTPqlgwEnUOxQDHMpBReyzuvtvd14TTLcAGgueFj7nzMsixDGQ0H4u7e2s4Wxj+OBGfl7gEQR2wI2e+gcH/RxmNHHjczFab2ZJw2SkePtEt/D0lb9UN30C1j9VzdbuZvRx2HfU028fEsZjZLOAigr8+x/R56XMsMAbPi5klzWwtsA94wt0jPy9xCQLrZ9lYu2/2Cne/GFgEfMLM3p7vgiIyFs/Vt4AzgHnAbuBL4fJRfyxmVgE8CHzS3ZsH27SfZaP9WMbkeXH3jLvPI3iG+wIzO2+QzU/KscQlCBqA6Tnz04BdearluLj7rvD3PuAhgubfXjM7DSD8vS9/FQ7bQLWPuXPl7nvDf7xZ4F7ebJqP6mMxs0KCD84fuPuPwsVj8rz0dyxj9bz0cPdDwDPAQiI+L3EJgpXAbDOrN7Mi4Gbg4TzXNGRmVm5mlT3TwNXAOoJj+INwsz8AfpKfCo/LQLU/DNxsZsVmVg/MBl7MQ31D1vMPNHQDwbmBUXwsZmbAd4EN7v7lnFVj7rwMdCxj9LzUmtmkcLoUeBewkajPS76vko/g1fhrCe4meA34y3zXM8zaTye4M+AlYH1P/UA18BSwOfw9Od+1DlD/fQRN8xTBXzAfGax24C/D87QJWJTv+odwLP8OvAK8HP7DPG20HwvwNoIuhJeBteHPtWPxvAxyLGPxvFwA/DqseR1wV7g80vOiISZERGIuLl1DIiIyAAWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIwgM3uHmf0s33WI5FIQiIjEnIJApB9mdms4LvxaM/t2OBBYq5l9yczWmNlTZlYbbjvPzF4IBzd7qGdwMzM708yeDMeWX2NmZ4QvX2FmPzSzjWb2g/CbsSJ5oyAQ6cPMzgXeTzDQ3zwgA3wQKAfWeDD437PAX4e7/BvwWXe/gOCbrD3LfwDc4+4XAm8l+EYyBKNjfpJgLPnTgSsiPiSRQRXkuwCRUeidwCXAyvCP9VKCQb6ywH+G23wf+JGZTQQmufuz4fLvAf8Vjg1V5+4PAbh7J0D4ei+6e0M4vxaYBfxP5EclMgAFgcjRDPieu995xEKzz/XZbrDxWQbr7unKmc6gf4eSZ+oaEjnaU8B7zWwK9D4vdibBv5f3htvcAvyPux8GDprZb4XLPwQ868F4+A1m9p7wNYrNrGwkD0JkqPSXiEgf7v6qmf0VwRPhEgQjjX4CaAPmmtlq4DDBdQQIhgVeGn7QbwU+HC7/EPBtM/ub8DXeN4KHITJkGn1UZIjMrNXdK/Jdh8jJpq4hEZGYU4tARCTm1CIQEYk5BYGISMwpCEREYk5BICIScwoCEZGY+//e/Y4ASZobHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_epoch.history['loss'])\n",
    "plt.plot(model_epoch.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ploting accuracy verses epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(model_epoch.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_epoch.history['accuracy'])\n",
    "plt.plot(model_epoch.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
